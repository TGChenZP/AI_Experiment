{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Investigation: Using \"Rock Paper Scissors\" like game to experiment with using Confidence Intervals on results that should be conclusive #\n",
    "### **with double mean CI instead of single mean CI* ###\n",
    "## AI Investigation Part 4+ ##\n",
    "\n",
    "#### *Goal: test effectiveness of Confidence Intervals on games that should have dominant strategy: 2+ options and non-binary game results. Also to validate the use of sample mean as statistic.* ####\n",
    "#### *Also amended previous problem of using single mean to construct CI* ####\n",
    "\n",
    "Creator: `Lang (Ron) Chen` 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import statistics as s\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Game\n",
    "\n",
    "### Rock Paper Scissors Like game:\n",
    "\n",
    "A: 0.25 +1; 0.25 0; 0.25 -1; 0.25 -2; \n",
    "`E(X) = -0.5; V(X) = 1.5`\n",
    "\n",
    "B: 0.25 +1; 0.25 0; 0.4 -1; 0.1 -2;\n",
    "`E(X) = -0.35; V(X) = 1.05`\n",
    "\n",
    "C: 0.25 +1; 0.25 0; 0.1 -1; 0.4 -2; \n",
    "`E(X) = -0.65; V(X) = 1.95`\n",
    "\n",
    "There are also varied versions for B:\n",
    "\n",
    "2. B: 0.25 +1; 0.25 0; 0.3 -1; 0.2 -2; `E(X) = -0.45; V(X) = 1.35`\n",
    "\n",
    "3. B: 0.25 +1; 0.25 0; 0.275 -1; 0.225 -2; `E(X) = -0.575; V(X) = 1.425`\n",
    "\n",
    "4. B: 0.25 +1; 0.25 0; 0.26 -1; 0.24 -2; `E(X) = -0.49; V(X) = 1.47`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOICE = ['A', 'B', 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Case 1\n",
    "# def winloss(player1, player2):\n",
    "#     if player1 == 'A':\n",
    "#         if player2 < 0.25:\n",
    "#             return 1\n",
    "#         elif player2 > 0.25 and player2 < 0.50:\n",
    "#             return 0\n",
    "#         elif player2 > 0.50 and player2 < 0.75:\n",
    "#             return -1\n",
    "#         elif player2 > 0.75:\n",
    "#             return -2\n",
    "        \n",
    "#     elif player1 == 'B':\n",
    "#         if player2 < 0.25:\n",
    "#             return 1\n",
    "#         elif player2 > 0.25 and player2 < 0.50:\n",
    "#             return 0\n",
    "#         elif player2 > 0.50 and player2 < 0.90:\n",
    "#             return -1\n",
    "#         elif player2 > 0.90:\n",
    "#             return -2\n",
    "        \n",
    "#     else:\n",
    "#         if player2 < 0.25:\n",
    "#             return 1\n",
    "#         elif player2 > 0.25 and player2 < 0.50:\n",
    "#             return 0\n",
    "#         elif player2 > 0.50 and player2 < 0.60:\n",
    "#             return -1\n",
    "#         elif player2 > 0.60:\n",
    "#             return -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Case 2\n",
    "# def winloss(player1, player2):\n",
    "#     if player1 == 'A':\n",
    "#         if player2 < 0.25:\n",
    "#             return 1\n",
    "#         elif player2 > 0.25 and player2 < 0.50:\n",
    "#             return 0\n",
    "#         elif player2 > 0.50 and player2 < 0.75:\n",
    "#             return -1\n",
    "#         elif player2 > 0.75:\n",
    "#             return -2\n",
    "        \n",
    "#     elif player1 == 'B':\n",
    "#         if player2 < 0.25:\n",
    "#             return 1\n",
    "#         elif player2 > 0.25 and player2 < 0.50:\n",
    "#             return 0\n",
    "#         elif player2 > 0.50 and player2 < 0.8:\n",
    "#             return -1\n",
    "#         elif player2 > 0.8:\n",
    "#             return -2\n",
    "        \n",
    "#     else:\n",
    "#         if player2 < 0.25:\n",
    "#             return 1\n",
    "#         elif player2 > 0.25 and player2 < 0.50:\n",
    "#             return 0\n",
    "#         elif player2 > 0.50 and player2 < 0.60:\n",
    "#             return -1\n",
    "#         elif player2 > 0.60:\n",
    "#             return -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Case 3\n",
    "# def winloss(player1, player2):\n",
    "#     if player1 == 'A':\n",
    "#         if player2 < 0.25:\n",
    "#             return 1\n",
    "#         elif player2 > 0.25 and player2 < 0.50:\n",
    "#             return 0\n",
    "#         elif player2 > 0.50 and player2 < 0.75:\n",
    "#             return -1\n",
    "#         elif player2 > 0.75:\n",
    "#             return -2\n",
    "        \n",
    "#     elif player1 == 'B':\n",
    "#         if player2 < 0.25:\n",
    "#             return 1\n",
    "#         elif player2 > 0.25 and player2 < 0.50:\n",
    "#             return 0\n",
    "#         elif player2 > 0.50 and player2 < 0.775:\n",
    "#             return -1\n",
    "#         elif player2 > 0.775:\n",
    "#             return -2\n",
    "        \n",
    "#     else:\n",
    "#         if player2 < 0.25:\n",
    "#             return 1\n",
    "#         elif player2 > 0.25 and player2 < 0.50:\n",
    "#             return 0\n",
    "#         elif player2 > 0.50 and player2 < 0.60:\n",
    "#             return -1\n",
    "#         elif player2 > 0.60:\n",
    "#             return -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 4\n",
    "def winloss(player1, player2):\n",
    "    if player1 == 'A':\n",
    "        if player2 < 0.25:\n",
    "            return 1\n",
    "        elif player2 > 0.25 and player2 < 0.50:\n",
    "            return 0\n",
    "        elif player2 > 0.50 and player2 < 0.75:\n",
    "            return -1\n",
    "        elif player2 > 0.75:\n",
    "            return -2\n",
    "        \n",
    "    elif player1 == 'B':\n",
    "        if player2 < 0.25:\n",
    "            return 1\n",
    "        elif player2 > 0.25 and player2 < 0.50:\n",
    "            return 0\n",
    "        elif player2 > 0.50 and player2 < 0.76:\n",
    "            return -1\n",
    "        elif player2 > 0.76:\n",
    "            return -2\n",
    "        \n",
    "    else:\n",
    "        if player2 < 0.25:\n",
    "            return 1\n",
    "        elif player2 > 0.25 and player2 < 0.50:\n",
    "            return 0\n",
    "        elif player2 > 0.50 and player2 < 0.60:\n",
    "            return -1\n",
    "        elif player2 > 0.60:\n",
    "            return -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(choice, CHOICE):\n",
    "    if \"Inconclusive\" in choice:\n",
    "        return 'Inconclusive'\n",
    "    if choice not in CHOICE:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNS = 1000000\n",
    "\n",
    "data = {'A': list(), 'B': list(), 'C': list()}\n",
    "\n",
    "sample = list()\n",
    "victory = list()\n",
    "for i in range(RUNS):\n",
    "    obs1 = random.sample(CHOICE, 1)[0]\n",
    "    obs2 = random.uniform(0, 1)\n",
    "    \n",
    "    data[obs1].append(winloss(obs1, obs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm for final choice**\n",
    "\n",
    "First: Manipulate data so that it is in a dictionary and the dictionary value is [mean, stdev, length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': [-0.49940753140083577, 1.117561833519635, 333351],\n",
       " 'B': [-0.4886360569411666, 1.108015539167295, 333467],\n",
       " 'C': [-0.6490986908056258, 1.235547578636235, 333182]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = dict()\n",
    "for choice in CHOICE:\n",
    "    tmp = list()\n",
    "    tmp.append(s.mean(data[choice]))\n",
    "    tmp.append(s.stdev(data[choice]))\n",
    "    tmp.append(len(data[choice]))\n",
    "    \n",
    "    stats[choice] = tmp\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_choice(stats):\n",
    "    \n",
    "    stats.sort(key = lambda x:x[1][0], reverse = True)\n",
    "\n",
    "    # Then tests whether the second, third and so forth values contain 0 within their joint Confidence Intervals\n",
    "    inconclusive_list = [stats[0][0]]\n",
    "    inconclusive = False\n",
    "    for i in range(1, len(stats)):\n",
    "        if in_range(construct_CI(stats[0], stats[i])):\n",
    "            inconclusive_list.append(stats[i][0])\n",
    "            inconclusive = True\n",
    "        else: # Because all values are sorted, if the current choice's joint Confidence Interval with the first ranked does not contain 0, then all the others wouldn't \n",
    "            break\n",
    "            \n",
    "    if inconclusive: # If inconclusive, return statement with the list of 'drawed' choices\n",
    "        return f'Inconclusive: the following came to a draw {inconclusive_list}'\n",
    "    \n",
    "    return stats[0][0] # Else, return the dominant strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_CI(stat1, stat2):\n",
    "    \"\"\" Uses Welch's approximation to construct a joint CI of two means, unknown population variance and assuming different variance \"\"\"\n",
    "    \n",
    "    xbar1 = stat1[1][0]\n",
    "    xbar2 = stat2[1][0]\n",
    "    s1 = stat1[1][1]\n",
    "    s2 = stat2[1][1]\n",
    "    n = stat1[1][2]\n",
    "    m = stat2[1][2]\n",
    "    \n",
    "    r = (s1**2 /n + s2**2 /m)**2 /(s1**4 /(n**2 * (n-1)) + s2**4 /(m**2 * (m-1)))\n",
    "    \n",
    "    q = scipy.stats.t.ppf(0.95, df = r)\n",
    "    \n",
    "    poolsd = np.sqrt(s1**2 /n + s2**2 /m)\n",
    "    \n",
    "    CI = (xbar1 - xbar2 - q * poolsd, xbar1 - xbar2 + q * poolsd)\n",
    "    \n",
    "    print(f'{stat1[0]} {stat2[0]}: {CI}')\n",
    "    print('\\n')\n",
    "    \n",
    "    return CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_range(CI):\n",
    "    \"\"\" Helper function to check whether 0 is within the Confidence Interval \"\"\"\n",
    "    \n",
    "    if CI[0] <= 0 and CI[1] >= 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': [-0.49940753140083577, 1.117561833519635, 333351],\n",
       " 'B': [-0.4886360569411666, 1.108015539167295, 333467],\n",
       " 'C': [-0.6490986908056258, 1.235547578636235, 333182]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B A: (0.0062884487871592825, 0.015254500132179107)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = final_choice(list(stats.items()))\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm successfully returned the dominant strategy: B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(result, CHOICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Emperical Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.490721"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "victory = list()\n",
    "for i in range(RUNS):\n",
    "    obs2 = random.uniform(0, 1)\n",
    "    victory.append(winloss(result, obs2))\n",
    "s.mean(victory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few words on experimental results:\n",
    "\n",
    "Using the two-mean CI, the experiment is returning much better results even for case 4 (51% vs 50%). However this does not rule out the urgent need for a more comprehensive experiment to determine what Confidence % to use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
