{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import statistics as s\n",
    "import scipy.stats\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF = 0.95\n",
    "RUNS = 100000\n",
    "TRIALRUNS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "statdict = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOICE = ['A', 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winloss(obs1, obs2, p):\n",
    "    if obs1 == 'A':\n",
    "        if obs2 < p:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    else:\n",
    "        if obs2 < 0.5:\n",
    "            return 1\n",
    "        else: \n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_choice(stats, conf):\n",
    "    \n",
    "    stats.sort(key = lambda x:x[1][0], reverse = True)\n",
    "\n",
    "    # Then tests whether the second, third and so forth values contain 0 within their joint Confidence Intervals\n",
    "    inconclusive_list = [stats[0][0]]\n",
    "    inconclusive = False\n",
    "    for i in range(1, len(stats)):\n",
    "        if in_range(construct_CI(stats[0], stats[i], conf)):\n",
    "            inconclusive_list.append(stats[i][0])\n",
    "            inconclusive = True\n",
    "        else: # Because all values are sorted, if the current choice's joint Confidence Interval with the first ranked does not contain 0, then all the others wouldn't \n",
    "            break\n",
    "            \n",
    "    if inconclusive: # If inconclusive, return statement with the list of 'drawed' choices\n",
    "        return f'Inconclusive: the following came to a draw {inconclusive_list}'\n",
    "    \n",
    "    return stats[0][0] # Else, return the dominant strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_CI(stat1, stat2, conf):\n",
    "    \"\"\" Uses Welch's approximation to construct a joint CI of two means, unknown population variance and assuming different variance \"\"\"\n",
    "    \n",
    "    xbar1 = stat1[1][0]\n",
    "    xbar2 = stat2[1][0]\n",
    "    s1 = stat1[1][1]\n",
    "    s2 = stat2[1][1]\n",
    "    n = stat1[1][2]\n",
    "    m = stat2[1][2]\n",
    "    \n",
    "    r = (s1**2 /n + s2**2 /m)**2 /(s1**4 /(n**2 * (n-1)) + s2**4 /(m**2 * (m-1)))\n",
    "    \n",
    "    q = scipy.stats.t.ppf(conf, df = r)\n",
    "    \n",
    "    poolsd = np.sqrt(s1**2 /n + s2**2 /m)\n",
    "    \n",
    "    CI = (xbar1 - xbar2 - q * poolsd, xbar1 - xbar2 + q * poolsd)\n",
    "    \n",
    "#     print(f'{stat1[0]} {stat2[0]}: {CI}')\n",
    "#     print('\\n')\n",
    "    \n",
    "    return CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_range(CI):\n",
    "    \"\"\" Helper function to check whether 0 is within the Confidence Interval \"\"\"\n",
    "    \n",
    "    if CI[0] <= 0 and CI[1] >= 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [0.51, 0.505, 0.501, 0.5005, 0.5]:\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for j in range(TRIALRUNS): \n",
    "\n",
    "\n",
    "        data = defaultdict(list) # Using defaultdict makes the code more adaptable to different games - and the validation function would ensure that the final choice is valid. However it is up to the user to double check as we are not hardcoding the choices\n",
    "\n",
    "        sample = list()\n",
    "        victory = list()\n",
    "\n",
    "        for i in range(RUNS):\n",
    "            obs1 = random.sample(CHOICE, 1)[0]\n",
    "            obs2 = random.uniform(0, 1)\n",
    "\n",
    "            data[obs1].append(winloss(obs1, obs2, p))\n",
    "\n",
    "        # This time we record the data for both players because we are interested in each's dominant strategy,  which will help us determine the equilibrium\n",
    "        # i.e. we are not as interested in, or equally interested in each's dominant strategy as well as the final equilibrium state\n",
    "\n",
    "        stats = dict()\n",
    "        for choice in CHOICE:\n",
    "            tmp = list()\n",
    "            tmp.append(s.mean(data[choice]))\n",
    "            tmp.append(s.stdev(data[choice]))\n",
    "            tmp.append(len(data[choice]))\n",
    "\n",
    "            stats[choice] = tmp\n",
    "\n",
    "        result = final_choice(list(stats.items()), CONF)\n",
    "        if result == 'A':\n",
    "            counter += 1\n",
    "\n",
    "    statdict[p] = counter/TRIALRUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {0.51: 0.92, 0.505: 0.47, 0.501: 0.12, 0.5005: 0.06, 0.5: 0.06})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, our test was conducted on random variables with variance = 1. Different scenarios (random variables with different variances) need to undergo re-testing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
